#assignment_005:Build activation function from scratch using pytorch tensors.

#Define function for the following activations:
# 1. Sigmoid
# 2. ReLu
# 3. Tanh
# 4. Softmax

import torch


def sigmoid(X):
    '''
    Computes sigmoid on input
    :param X: Inputs as Torch Tensors
    :return: y
    '''
    # your code here...
    return y

def relu(X):
    '''
    Computes relu on input
    :param X: Inputs as Torch Tensors
    :return: y
    '''
    # your code here...
    return y

def softmax(X):
    '''
    Computes softmax on input
    :param X: Inputs as Torch Tensors
    :return: y
    '''
    # your code here...
    return y

def tanh(X):
    '''
    Computes tanh on input
    :param X: Inputs as Torch Tensors
    :return: y
    '''
    # your code here...
    return y